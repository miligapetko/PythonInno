{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAS Innovate Workbench Workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, recall_score\n",
    "\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "\n",
    "from sasviya.ml.tree import ForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bank.csv', 'Bank_Score.csv', 'Bank_Train.csv']\n"
     ]
    }
   ],
   "source": [
    "# List all files in the directory\n",
    "files = os.listdir()\n",
    "\n",
    "# Filter files that end with .csv\n",
    "csv_files = [f for f in files if f.endswith('.csv')]\n",
    "\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file as a DataFrame\n",
    "bank = pd.read_csv(csv_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AccountID</th>\n",
       "      <th>Status</th>\n",
       "      <th>Customer_Value</th>\n",
       "      <th>Age</th>\n",
       "      <th>Home_Flag</th>\n",
       "      <th>Homeval</th>\n",
       "      <th>Inc</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Activity_Status</th>\n",
       "      <th>AvgSale3Yr</th>\n",
       "      <th>...</th>\n",
       "      <th>AvgSale3Yr_DP</th>\n",
       "      <th>LastProdAmt</th>\n",
       "      <th>CntPur3Yr</th>\n",
       "      <th>CntPurLife</th>\n",
       "      <th>CntPur3Yr_DP</th>\n",
       "      <th>CntPurLife_DP</th>\n",
       "      <th>CntTotPromo</th>\n",
       "      <th>MnthsLastPur</th>\n",
       "      <th>Cnt1Yr_DP</th>\n",
       "      <th>CustTenure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5200000001</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>57600</td>\n",
       "      <td>52106</td>\n",
       "      <td>24</td>\n",
       "      <td>High</td>\n",
       "      <td>5.71</td>\n",
       "      <td>...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5200000002</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>57587</td>\n",
       "      <td>52106</td>\n",
       "      <td>24</td>\n",
       "      <td>High</td>\n",
       "      <td>5.71</td>\n",
       "      <td>...</td>\n",
       "      <td>5.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5200000003</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>44167</td>\n",
       "      <td>42422</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>12.80</td>\n",
       "      <td>...</td>\n",
       "      <td>13.00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5200000004</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>90587</td>\n",
       "      <td>59785</td>\n",
       "      <td>32</td>\n",
       "      <td>High</td>\n",
       "      <td>21.60</td>\n",
       "      <td>...</td>\n",
       "      <td>20.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5200000005</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>100313</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>7.33</td>\n",
       "      <td>...</td>\n",
       "      <td>7.60</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AccountID  Status Customer_Value   Age  Home_Flag  Homeval    Inc  Pr  \\\n",
       "0  5200000001       1              A   NaN          0    57600  52106  24   \n",
       "1  5200000002       1              A   NaN          0    57587  52106  24   \n",
       "2  5200000003       1              A   NaN          0    44167  42422   0   \n",
       "3  5200000004       0              A  68.0          0    90587  59785  32   \n",
       "4  5200000005       0              A   NaN          0   100313      0   0   \n",
       "\n",
       "  Activity_Status  AvgSale3Yr  ...  AvgSale3Yr_DP  LastProdAmt  CntPur3Yr  \\\n",
       "0            High        5.71  ...           5.25         10.0          7   \n",
       "1            High        5.71  ...           5.25         10.0          7   \n",
       "2            High       12.80  ...          13.00         12.0          5   \n",
       "3            High       21.60  ...          20.00         25.0          5   \n",
       "4            High        7.33  ...           7.60         10.0          6   \n",
       "\n",
       "   CntPurLife  CntPur3Yr_DP  CntPurLife_DP  CntTotPromo  MnthsLastPur  \\\n",
       "0          22             4              6           20             5   \n",
       "1          22             4              6           20             5   \n",
       "2          16             3              8           27            16   \n",
       "3          21             2              7           19            15   \n",
       "4          38             5             19           13            24   \n",
       "\n",
       "   Cnt1Yr_DP  CustTenure  \n",
       "0          9          92  \n",
       "1          9          92  \n",
       "2         11          91  \n",
       "3          9         123  \n",
       "4          6         128  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displaying dataframe\n",
    "bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding datasets dimensions\n",
    "print(\"Bank_Train data shape:\", bank.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note Score set is bigger than Train.\n",
    "\n",
    "*DISCUSSION:* Can consider adding synthetic data to Train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understanding column format\n",
    "bank.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing categorical variables\n",
    "bank[\"AccountID\"] = bank[\"AccountID\"].astype('category')\n",
    "bank[\"Status\"] = bank[\"Status\"].astype('category')\n",
    "bank[\"Customer_Value\"] = bank[\"Customer_Value\"].astype('category')\n",
    "bank[\"Home_Flag\"] = bank[\"Home_Flag\"].astype('category')\n",
    "bank['Activity_Status'] = bank['Activity_Status'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing variable exploration\n",
    "bank.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Demog_Age and AvgSale3Yr_DP have missing data, but missing 20-25% of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding duplicated data\n",
    "bank.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary statistics\n",
    "bank.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable_types(df):\n",
    "    # Separate continuous and categorical variables\n",
    "    continuous_vars = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "    categorical_vars = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    # Plot histograms for continuous variables in one figure\n",
    "    plt.figure(figsize=(20, 50))\n",
    "    for i, col in enumerate(continuous_vars):\n",
    "        plt.subplot(len(continuous_vars)//2 + 1, 2, i + 1)\n",
    "        plt.hist(df[col], bins=20, edgecolor='black')\n",
    "        plt.title(f'{col} Distribution (Histogram)')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot bar charts for categorical variables in another figure\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, col in enumerate(categorical_vars):\n",
    "        plt.subplot(len(categorical_vars)//2 + 1, 2, i + 1)\n",
    "        value_counts = df[col].value_counts()\n",
    "        plt.bar(value_counts.index, value_counts.values, color='skyblue')\n",
    "        plt.title(f'{col} Distribution (Bar Chart)')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variable_types(bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Age is skewed to the left, have some customers under 18- consider dropping unless they are high worth customers.\n",
    "* AvgSale3Yr, AvgSale3Yr_DP, AvgSaleLife and LastProdAmt are all highly concentrated in one bucket with samll number of positive outliers.\n",
    "* Cnt1Yr_DP, CntPur3Yr, CntPur3Yr_DP, CntPurLife, CntPurLife_DP, CntTotPromo, CustTenure are all skewed to the right.\n",
    "* Imbalanced dataset, with about 20% of data buying the insurance product and 80% not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numeric columns\n",
    "numeric_cols = bank.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Calculate mean of numeric columns\n",
    "mean_values = bank[numeric_cols].mean()\n",
    "\n",
    "# Fill missing values in numeric columns with their respective means\n",
    "bank[numeric_cols] = bank[numeric_cols].fillna(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lable encoding\n",
    "\n",
    "* did not use one-hot encoding because want to preserve ordinality of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns excluding 'Activity_Status' and 'Customer_Value'\n",
    "categorical_cols = [col for col in bank.select_dtypes(include=['object']).columns if col != 'Activity_Status' and col != 'Customer_Value']\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode each categorical column using LabelEncoder\n",
    "for col in categorical_cols:\n",
    "    bank[col] = label_encoder.fit_transform(bank[col])\n",
    "\n",
    "# Mapping for 'Activity_Status' and 'Customer_Value'\n",
    "label_encoding = {\n",
    "    'Activity_Status': {'High': 0, 'Average': 1, 'Low': 2},\n",
    "    'Customer_Value': {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4}\n",
    "}\n",
    "\n",
    "# Apply mapping\n",
    "for col, mapping in label_encoding.items():\n",
    "    bank[col] = bank[col].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 108600 entries, 0 to 108599\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   AccountID        108600 non-null  int64  \n",
      " 1   Status           108600 non-null  int64  \n",
      " 2   Customer_Value   108600 non-null  int64  \n",
      " 3   Age              108600 non-null  float64\n",
      " 4   Home_Flag        108600 non-null  int64  \n",
      " 5   Homeval          108600 non-null  int64  \n",
      " 6   Inc              108600 non-null  int64  \n",
      " 7   Pr               108600 non-null  int64  \n",
      " 8   Activity_Status  108600 non-null  int64  \n",
      " 9   AvgSale3Yr       108600 non-null  float64\n",
      " 10  AvgSaleLife      108600 non-null  float64\n",
      " 11  AvgSale3Yr_DP    108600 non-null  float64\n",
      " 12  LastProdAmt      108600 non-null  float64\n",
      " 13  CntPur3Yr        108600 non-null  int64  \n",
      " 14  CntPurLife       108600 non-null  int64  \n",
      " 15  CntPur3Yr_DP     108600 non-null  int64  \n",
      " 16  CntPurLife_DP    108600 non-null  int64  \n",
      " 17  CntTotPromo      108600 non-null  int64  \n",
      " 18  MnthsLastPur     108600 non-null  int64  \n",
      " 19  Cnt1Yr_DP        108600 non-null  int64  \n",
      " 20  CustTenure       108600 non-null  int64  \n",
      "dtypes: float64(5), int64(16)\n",
      "memory usage: 17.4 MB\n"
     ]
    }
   ],
   "source": [
    "# checking result of parsing and imputation\n",
    "bank.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bank.drop(['Status'], axis=1)\n",
    "y = bank['Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86880, 20)\n",
      "(21720, 20)\n",
      "(86880,)\n",
      "(21720,)\n"
     ]
    }
   ],
   "source": [
    "# checking split results\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python sklearn models\n",
    "\n",
    "* Decision Tree\n",
    "* Random Forest\n",
    "* Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8302255985267035\n",
      "Test Accuracy: 0.8246777163904235\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree, max 3 layers\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, dt.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_valid, dt.predict(X_valid))\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               0.941378\n",
       "1               0.381215\n",
       "accuracy        0.824678\n",
       "macro avg       0.661297\n",
       "weighted avg    0.824678\n",
       "Name: recall, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_report = classification_report(y_valid, dt.predict(X_valid), output_dict=True)\n",
    "pd.DataFrame(test_report).T[\"recall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "dt_feat = pd.DataFrame(dt.feature_importances_, index=X_train.columns, columns=['feat_importance'])\n",
    "dt_feat.sort_values('feat_importance').tail(8).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9999769797421731\n",
      "Test Accuracy: 0.8408839779005525\n",
      "0               0.882873\n",
      "1               0.681326\n",
      "accuracy        0.840884\n",
      "macro avg       0.782099\n",
      "weighted avg    0.840884\n",
      "Name: recall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Random forest, with SMOTE\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "#    ('scaler', StandardScaler()),\n",
    "#    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('SMOTEENN', SMOTE(random_state=42)),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_valid, pipeline.predict(X_valid))\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "test_report = classification_report(y_valid, pipeline.predict(X_valid), output_dict=True)\n",
    "print(pd.DataFrame(test_report).T[\"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8229166666666666\n",
      "Test Accuracy: 0.8151012891344384\n",
      "0               0.849666\n",
      "1               0.683757\n",
      "accuracy        0.815101\n",
      "macro avg       0.766711\n",
      "weighted avg    0.815101\n",
      "Name: recall, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting, with SMOTE\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.7,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "#    ('scaler', StandardScaler()),\n",
    "#    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('SMOTEENN', SMOTE(random_state=42)),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, pipeline.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_valid, pipeline.predict(X_valid))\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "test_report = classification_report(y_valid, pipeline.predict(X_valid), output_dict=True)\n",
    "print(pd.DataFrame(test_report).T[\"recall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SAS Models\n",
    "\n",
    "* Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7982504604051566\n",
      "Test Accuracy: 0.7810313075506445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0               0.783193\n",
       "1               0.772818\n",
       "accuracy        0.781031\n",
       "macro avg       0.778005\n",
       "weighted avg    0.781031\n",
       "Name: recall, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAS Decision Tree, with SMOTE\n",
    "\n",
    "model = ForestClassifier(\n",
    "    random_state=70\n",
    ")\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "#    ('scaler', StandardScaler(with_mean=True)),\n",
    "#    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('SMOTEENN', SMOTE(random_state=42)),\n",
    "    ('classifier', model)\n",
    "])\n",
    "\n",
    "pipeline2.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, pipeline2.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_valid, pipeline2.predict(X_valid))\n",
    "\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "test_report = classification_report(y_valid, pipeline2.predict(X_valid), output_dict=True)\n",
    "pd.DataFrame(test_report).T[\"recall\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Workbench Python",
   "language": "python",
   "name": "workbench_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
